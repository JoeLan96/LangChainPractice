{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 基础入门\n",
    "本快速入门将介绍使用语言模型的基础知识。它将介绍两种不同类型的模型 - LLMs 和 ChatModels。\n",
    "\n",
    "然后，它将介绍如何使用 PromptTemplates 设置这些模型的输入格式，以及如何使用输出分析器来处理输出。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "991c788db8bb91aa"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# 如果你需要通过代理端口访问，你需要如下配置\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ[\"HTTP_PROXY\"] = 'http://127.0.0.1:7890'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T13:41:01.964391300Z",
     "start_time": "2024-03-25T13:41:01.943883800Z"
    }
   },
   "id": "546138c87992f3b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型\n",
    "这两个 llm 对象 chat_model 都是表示特定模型配置的对象。您可以使用 和 others 等 temperature 参数初始化它们，然后传递它们。\n",
    "它们之间的主要区别在于它们的输入和输出架构。LLM对象将**字符串**作为输入和输出字符串。ChatModel 对象将**消息列表**作为输入并输出消息。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b51c5bedf08ea2bf"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T13:41:04.651833400Z",
     "start_time": "2024-03-25T13:41:03.451397Z"
    }
   },
   "id": "94bb43bb1bd99f79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "当我们调用 ChatModel LLM 时，我们可以看到它之间的区别。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "175b4d500085de7c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "\n",
      "\n",
      "\"Spectrum Socks\" or \"Rainbow Footwear Co.\"\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='Rainbow Sock Co.' response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 22, 'total_tokens': 28}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "response1 = llm.invoke(text)\n",
    "print(type(response1))\n",
    "print(response1)\n",
    "# >> Feetful of Fun\n",
    "\n",
    "response2 = chat_model.invoke(messages)\n",
    "print(type(response2))\n",
    "print(response2)\n",
    "# >> AIMessage(content=\"Socks O'Color\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T13:44:49.087624300Z",
     "start_time": "2024-03-25T13:44:46.248580900Z"
    }
   },
   "id": "8269c962a676ce2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prompt Templates 提示模板"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ae0e3d1a9b15769"
  },
  {
   "cell_type": "markdown",
   "source": [
    "大多数LLM应用程序不会将用户输入直接传递到 LLM.通常，他们会将用户输入添加到更大的文本中，称为提示模板，该文本提供有关特定任务的额外上下文。\n",
    "\n",
    "与原始字符串格式相比，使用这些格式的优势有几个。您可以“部分”删除变量 - 例如，一次只能格式化部分变量。您可以将它们组合在一起，轻松地将不同的模板组合到一个提示中。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9b8f4813e0d4fe"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'What is a good name for a company that makes colorful socks?'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"colorful socks\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T13:46:58.232434100Z",
     "start_time": "2024-03-25T13:46:58.174026200Z"
    }
   },
   "id": "9298c2dbab80cfd6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`PromptTemplate` 还可用于生成消息列表。在这种情况下，提示不仅包含有关内容的信息，还包含每条消息（其角色、在列表中的位置等）。\n",
    "在这里，最常发生的是 `ChatPromptTemplate` 是 `ChatMessageTemplates` 的列表.\n",
    "每个 `ChatMessageTemplate` 都包含有关如何格式化的说明 `ChatMessage` - 其角色，然后还有其内容。让我们在下面看一下："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "744c271f3924c2d0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-25T13:47:53.599967300Z",
     "start_time": "2024-03-25T13:47:53.555930500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[SystemMessage(content='You are a helpful assistant that translates English to French.'),\n HumanMessage(content='I love programming.')]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chat_prompt.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "ChatPromptTemplates 也可以用其他方式构建 - 有关更多详细信息，请参阅 [prompts](https://python.langchain.com/docs/modules/model_io/prompts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d2b136057ec2a2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output parsers 输出分析器\n",
    "\n",
    "`OutputParser` 将语言模型的原始输出转换为可在下游使用的格式。 `OutputParser` 有几种主要类型，包括：\n",
    "\n",
    "- 将文本转换为 `LLM` 结构化信息 （e.g. JSON）\n",
    "\n",
    "- 将 `ChatMessage` 转换为字符串\n",
    "\n",
    "- 将除消息之外的调用返回的额外信息（如 OpenAI 函数调用）转换为字符串。\n",
    "\n",
    "有关此内容的完整信息，请参阅有关[output_parsers](https://python.langchain.com/docs/modules/model_io/output_parsers)的部分。\n",
    "\n",
    "在本入门指南中，我们使用一个简单的指南来解析逗号分隔值的列表。|"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6070a850c5ed2c57"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['hi', 'bye']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "output_parser.parse(\"hi, bye\")\n",
    "# >> ['hi', 'bye']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T14:00:48.165979700Z",
     "start_time": "2024-03-25T14:00:48.118949700Z"
    }
   },
   "id": "4fbd1dbde1930944"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Composing with LCEL 使用 LCEL 作曲\n",
    "\n",
    "我们现在可以将所有这些组合成一个链条。此链将获取输入变量，将这些变量传递给提示模板以创建提示，\n",
    "将提示传递给语言模型，然后通过（可选）输出解析器传递输出。这是捆绑模块化逻辑的便捷方法。让我们看看它的实际效果吧！"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adcb1e0edaa6229e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "template = \"Generate a list of 5 {text}.\\n\\n{format_instructions}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(template)\n",
    "chat_prompt = chat_prompt.partial(format_instructions=output_parser.get_format_instructions())\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "chain = chat_prompt | chat_model | output_parser\n",
    "chain.invoke({\"text\": \"colors\"})\n",
    "# >> ['red', 'blue', 'green', 'yellow', 'orange']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9de76e638bd96d1c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "60f28ad7073437db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fb272045829cf5f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
